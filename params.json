{"name":"Pml-assignment","tagline":"Practical Machine Learning - Assignment for peer review","body":"\r\n<body>\r\n<h1>Assignment write-up</h1>\r\n\r\n<p>First I am going to load libraies that will be used</p>\r\n\r\n<pre><code>library(randomForest)\r\n</code></pre>\r\n\r\n<p>Then I load the training data set.</p>\r\n\r\n<pre><code>data_train &lt;- read.table(file=&#39;pml-training.csv&#39;, header=T, sep=&#39;,&#39;, na.strings = c(&quot;NA&quot;,&quot;#DIV/0!&quot;))\r\nstr(data_tran)\r\n</code></pre>\r\n\r\n<p>At first glance there are many variables that contain N/A values, so I leave out all, that have more than 100 missing values. I also remove first 7 variables that serve for the case identification purpose. The aim of the model is to predict activity class from device data, these variables are obsolete outside data exploration.</p>\r\n\r\n<pre><code>keep &lt;- c()\r\nfor (i in 1:160){\r\n  if (length(which(is.na(data_train[,i])))&lt;100){keep &lt;- c(keep,i)}\r\n}\r\n\r\ndata_clean &lt;- data_train[,keep[8:length(keep)]]\r\n</code></pre>\r\n\r\n<p>Since there are more than 19000 observations in the data, I will simply split the dataset into two parts - training for model building (60%) and testing for model evaluation (40%).</p>\r\n\r\n<pre><code>set.seed(123)\r\nindex_train &lt;- createDataPartition(y=data_clean$classe,p=0.6,list=F)\r\ntrain &lt;- data_clean[index_train,]\r\ntest &lt;- data_clean[-index_train,]\r\n</code></pre>\r\n\r\n<p>First thing I try is the randomForrest algorithm as this is a classification problem. I do not do any further pre-processing of the data because this algorithm does not require it. The first model is built on the training set.</p>\r\n\r\n<pre><code>modelFit &lt;- randomForest(classe~.,data=train)\r\nmodelFit$confusion\r\n     A    B    C    D    E  class.error\r\nA 3345    1    0    1    1 0.0008960573\r\nB   11 2264    4    0    0 0.0065818341\r\nC    1   18 2030    5    0 0.0116845180\r\nD    1    0   26 1901    2 0.0150259067\r\nE    0    0    2    5 2158 0.0032332564\r\n</code></pre>\r\n\r\n<p>After careful examination of the confusion matrix it seems that the very first model has very reasonable accuracy of over 99%. I run the model on the remaining 40% of the data to evaluate its out of sample error.</p>\r\n\r\n<pre><code>pred &lt;- test$classe==predict(modelFit,test[,-53])\r\ntable(pred)\r\npred\r\nFALSE  TRUE \r\n   46  7800 \r\nas.numeric(table(pred)[1]/(table(pred)[1]+table(pred)[2]))\r\n0.00586286\r\n</code></pre>\r\n\r\n<p>It seems to be well below 0.5%. This kind of accuracy for this model should be expected for all data collected in similar manner. I consider the model accurate enough for purposes of activity class prediction so I will not be trying more complicated algorithms.</p>\r\n\r\n<p>Finally, I run the model on the 20 test cases to submit for the second part of the assignment.</p>\r\n\r\n<pre><code>data_test &lt;- read.table(file=&#39;pml-testing.csv&#39;, header=T, sep=&#39;,&#39;, na.strings = c(&quot;NA&quot;,&quot;#DIV/0!&quot;))\r\ndatat_clean &lt;- data_test[,keep[8:length(keep)]]\r\npred_test &lt;- predict(modelFit,datat_clean[,-53])\r\n</code></pre>\r\n\r\n</body>\r\n\r\n</html>\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}